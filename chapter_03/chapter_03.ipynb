{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 Data Preparation\n",
    "\n",
    "## The Problem Understanding Phase\n",
    "\n",
    "It's important to know *what* questions you are trying to answer.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "1.  Learn about potential customers. What are the defining characteristics of those who both do and do not bank with us?\n",
    "2.  Develop a way to identify customers who are likely to bank with us in the future. This will save time and money by preventing our chasing customers who will likely not choose us in the future.\n",
    "\n",
    "### Translating These Objectives into a Data Science Problem\n",
    "\n",
    "How do we use DS to accomplish our objectives?\n",
    "\n",
    "1.  There are many ways to learn about potential customers.\n",
    "    1.  Exploratory Data Analysis to find relationships among variables. (ex. a histogram of age overlaid with responses to a yes/no question to determine if age has a bearing on customer response.)\n",
    "    2.  Use clustering to find any potential natural groupings within potential customers. (ex. group younger/better-educated vs older/less-educated and see if these clusters differ in their response to our marketing.)\n",
    "    3.  Use association rules to see if there are useful relationships between subsets of records. (ex. if the rule, \"if cell phone, then response = \"yes\" we could focus our efforts on only those potential customers who have cell phones.)\n",
    "2.  Develop models to identify likely positive respondents. Note that because the yes/no response is categorical we can use classification models but *not* estimation models.\n",
    "    1.  Develop the best models we can using the following algorithms:\n",
    "        -   decision trees\n",
    "        -   random forests\n",
    "        -   naive Bayes classification\n",
    "        -   neural networks\n",
    "        -   logistic regression\n",
    "    2.  Evaluate each model on some predetermined criteria (such as the cost of misclassification). and compare the models against each other.\n",
    "    3.  Consult with management regarding our findings.\n",
    "\n",
    "## The Data Preparation Phase\n",
    "\n",
    "Every data set has its own, unique needs in terms of cleaning and preparation. In this chapter we will focus on:\n",
    "\n",
    "-   adding an index field\n",
    "-   changing misleading field values\n",
    "-   re-expressing categorical data as numeric\n",
    "-   standardizing the numeric fields\n",
    "-   identifying outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding an Index Field\n",
    "\n",
    "Not all data sets include a natural ID or indexing variable. It's useful to add on to:\n",
    "\n",
    "1.  have some way to identify each observation\n",
    "2.  be able to restore the original ordering of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train = pd.read_csv(\"data/bank_marketing_training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to know how many observations there are in our data set. `.shape` will get number of rows and columns that are in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a new variable to serve as the index. I prefer my index variable to be in the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train.insert(0, \"index\", pd.Series(range(bank_train.shape[0])))\n",
    "\n",
    "bank_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Misleading Field Values\n",
    "\n",
    "The variable *days_since_previous* is a count of the number of days since the client was last contacted. The field is numeric so we can use a histogram to visualize and sanity check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bank_train[\"days_since_previous\"], edgecolor=\"black\")\n",
    "plt.xlabel(\"days_since_previous\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.title(\"Histogram of days_since_previous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that *many* of the values are near 1000 (999 to be exact). After some investigation we discover that 999 was used as a sentinel to indicate that customer had never been contacted.\n",
    "\n",
    "We will change the value *999* to *NaN*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train[\"days_since_previous\"] = bank_train[\"days_since_previous\"].replace({999: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bank_train[\"days_since_previous\"], edgecolor=\"black\")\n",
    "plt.xlabel(\"days_since_previous\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.title(\"Histogram of days_since_previous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Expression of Categorical Data as Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(bank_train[\"education\"].unique(), bank_train[\"education\"].value_counts(sort=False))\n",
    "plt.title(\"Barplot of education\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the *education* variable is categorical there is no inherent ordering of the values. In other words, R can't know that *university.degree* represents more education than *basic.4y*. To provide this information to our algorithms we transform the data into numeric values.\n",
    "\n",
    "| Categorical Value   | Numeric Value |\n",
    "|---------------------|---------------|\n",
    "| illiterate          | 0             |\n",
    "| basic.4y            | 4             |\n",
    "| basic.6y            | 6             |\n",
    "| basic.9y            | 9             |\n",
    "| high.school         | 12            |\n",
    "| professional.course | 12            |\n",
    "| university.degree   | 16            |\n",
    "| unknown             | missing       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the *education_numeric* variable and add it to the data set. This will be used to replace the categorical values with numeric ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train[\"education_numeric\"] = bank_train[\"education\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary mapping the categorical values to the numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_edu = {\n",
    "    \"education_numeric\": {\n",
    "        \"illiterate\": 0,\n",
    "        \"basic.4y\": 4,\n",
    "        \"basic.6y\": 6,\n",
    "        \"basic.9y\": 9,\n",
    "        \"high.school\": 12,\n",
    "        \"professional.course\": 12,\n",
    "        \"university.degree\": 16,\n",
    "        \"unknown\": np.NaN,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use the dictionary to replace the values in the education_numeric column. `replace()` will match the keys of the dict to column names and replace the values in that column with the values of the dict. Like magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train.replace(dict_edu, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bank_train[\"education_numeric\"], edgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing the Numeric Fields\n",
    "\n",
    "Certain algorithms perform better when the numeric fields used as their input have been standardized so that the field's mean equals 0 and its standard deviation = 1 as follows:\n",
    "\n",
    "$$\n",
    "z = Standardized Value = \\frac{x-\\overline{x}}{s} = \\frac{Data value - mean}{Standard deviation}\n",
    "$$\n",
    "\n",
    "Positive z-values represent the number of standard deviations above the mean, negative as those below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train[\"age_z\"] = stats.zscore(bank_train[\"age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`zscore()` calculates the z-score for each value in the specified column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Outliers\n",
    "\n",
    "Once the numeric fields are normalized we can use the z-values to identify outliers.\n",
    "\n",
    "For example, consider a theoretical field named *number_of_contacts* representing the number of times a potential customer was contacted during the marketing campaign. The mean number of contacts per customer is 2.6 with a standard deviation of 2.7. We obtain the standardized field as follows:\n",
    "\n",
    "$$\n",
    "number\\_of\\_contacts\\_z = \\frac{number\\_of\\_contacts - 2.6}{2.7}\n",
    "$$\n",
    "\n",
    "A rough rule of thumb is any data value is an outlier if its z-value is greater than 3 or less than -3.\n",
    "\n",
    "You should consult with your client as to how to handle outliers. **They should not be removed automatically, nor changed.** These unusual values may provide valuable insight into the data.\n",
    "\n",
    "We'll use the `age-z` variable we created earlier. To isolate observations of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_outliers = bank_train.query(\"age_z > 3 | age_z < -3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`age_outliers`is a dataframe composed of only the outliers.\n",
    "\n",
    "We can sort it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train_storted = bank_train.sort_values([\"age_z\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sort_values()` sorts the df by the specified column(s). `ascending=False` sorts in descending order.\n",
    "\n",
    "If, for example, we want to report the age and maritial status of the 15 people wit the largest `age_z` vlues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train_storted[[\"age\", \"marital\"]].head(n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The double brackets are used to specify the columns we want to display. We are indexing inot the dataframe with a list of column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Working With the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>days_since_previous</th>\n",
       "      <th>previous</th>\n",
       "      <th>previous_outcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital    education  default housing loan    contact  \\\n",
       "0   56    housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57     services  married  high.school  unknown      no   no  telephone   \n",
       "2   41  blue-collar  married      unknown  unknown      no   no  telephone   \n",
       "3   25     services   single  high.school       no     yes   no  telephone   \n",
       "4   29  blue-collar   single  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  days_since_previous  previous  \\\n",
       "0   may         mon  ...         1                  999         0   \n",
       "1   may         mon  ...         1                  999         0   \n",
       "2   may         mon  ...         1                  999         0   \n",
       "3   may         mon  ...         1                  999         0   \n",
       "4   may         mon  ...         1                  999         0   \n",
       "\n",
       "   previous_outcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0       nonexistent          1.1          93.994          -36.4      4.857   \n",
       "1       nonexistent          1.1          93.994          -36.4      4.857   \n",
       "2       nonexistent          1.1          93.994          -36.4      4.857   \n",
       "3       nonexistent          1.1          93.994          -36.4      4.857   \n",
       "4       nonexistent          1.1          93.994          -36.4      4.857   \n",
       "\n",
       "   nr.employed  response  \n",
       "0         5191        no  \n",
       "1         5191        no  \n",
       "2         5191        no  \n",
       "3         5191        no  \n",
       "4         5191        no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "bank_train = pd.read_csv(\"data/bank_marketing_training\", index_col=False)\n",
    "\n",
    "bank_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Derive an index field and add it to the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train.insert(0, \"index\", pd.Series(range(bank_train.shape[0])))\n",
    "\n",
    "bank_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. For the *days_since_previous* field, change the field value *999* to the appropriate code for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train[\"days_since_previous\"] = bank_train[\"days_since_previous\"].replace({999: np.nan})\n",
    "\n",
    "bank_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. For the `education` field, reexpress the field values as the numeric values shown in the table below.\n",
    "\n",
    "| Categorical Value   | Numeric Value |\n",
    "|---------------------|---------------|\n",
    "| illiterate          | 0             |\n",
    "| basic.4y            | 4             |\n",
    "| basic.6y            | 6             |\n",
    "| basic.9y            | 9             |\n",
    "| high.school         | 12            |\n",
    "| professional.course | 12            |\n",
    "| university.degree   | 16            |\n",
    "| unknown             | missing       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# craate the new variable\n",
    "bank_train[\"education_numeric\"] = bank_train[\"education\"]\n",
    "\n",
    "# dict mapping of education values to ecucation_numeric values\n",
    "ed_levels = {\n",
    "    \"education_numeric\": {\n",
    "        \"illiterate\": 0,\n",
    "        \"basic.4y\": 4,\n",
    "        \"basic.6y\": 6,\n",
    "        \"basic.9y\": 9,\n",
    "        \"high.school\": 12,\n",
    "        \"professional.course\": 12,\n",
    "        \"university.degree\": 16,\n",
    "        \"unknown\": \"missing\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# do the replacement\n",
    "bank_train.replace(ed_levels, inplace=True)\n",
    "\n",
    "# reorder the columns to place education_numeric next to education\n",
    "vars = bank_train.columns.tolist()\n",
    "idx = bank_train.columns.get_loc(\"education\")\n",
    "vars = vars[0 : idx + 1] + vars[-1:] + vars[idx + 1 : -1]\n",
    "bank_train = bank_train[vars]\n",
    "\n",
    "bank_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Standardize the field `age`. Print out a list of the first 10 records, including the variables `age` and `age_z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train[\"age_z\"] = stats.zscore(bank_train[\"age\"])\n",
    "\n",
    "vars = bank_train.columns.tolist()\n",
    "idx = bank_train.columns.get_loc(\"age\")\n",
    "vars = vars[0 : idx + 1] + vars[-1:] + vars[idx + 1 : -1]\n",
    "bank_train = bank_train[vars]\n",
    "\n",
    "bank_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Obtain a listing of all records that are outliers according to the field `age_z`. Print out a listing of the 10 largest `age_z` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_outliers = bank_train.query(\"age_z > 3 | age_z < -3\").sort_values([\"age_z\"], ascending=False)\n",
    "\n",
    "age_outliers.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. For the `job` field, combine the jobs with less than 5% of the records into a field called `other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_counts = bank_train[\"job\"].value_counts()\n",
    "threshold = len(bank_train) * 0.05\n",
    "other_jobs = job_counts[job_counts < threshold].index\n",
    "\n",
    "bank_train[\"job\"] = bank_train[\"job\"].apply(lambda x: \"other\" if x in other_jobs else x)\n",
    "\n",
    "bank_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Rename the `default` predictor to `credit_default`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train.rename(columns={\"default\": \"credit_default\"}, inplace=True)\n",
    "\n",
    "bank_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. For the variable `month`, change the field values to 1–12, but keep the variable as categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train[\"month\"] = bank_train[\"month\"].replace(\n",
    "    {\n",
    "        \"jan\": 1,\n",
    "        \"feb\": 2,\n",
    "        \"mar\": 3,\n",
    "        \"apr\": 4,\n",
    "        \"may\": 5,\n",
    "        \"jun\": 6,\n",
    "        \"jul\": 7,\n",
    "        \"aug\": 8,\n",
    "        \"sep\": 9,\n",
    "        \"oct\": 10,\n",
    "        \"nov\": 11,\n",
    "        \"dec\": 12,\n",
    "    }\n",
    ")\n",
    "\n",
    "bank_train[\"month\"] = bank_train[\"month\"].astype(\"category\")\n",
    "\n",
    "bank_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. Do the following for the `duration` field.\n",
    "\n",
    "    1. Standardize the variable.\n",
    "    1. Identify how many outliers there are and identify the most extreme outlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the variable\n",
    "bank_train[\"duration_z\"] = stats.zscore(bank_train[\"duration\"])\n",
    "\n",
    "vars = bank_train.columns.tolist()\n",
    "idx = bank_train.columns.get_loc(\"duration\")\n",
    "vars = vars[0 : idx + 1] + vars[-1:] + vars[idx + 1 : -1]\n",
    "bank_train = bank_train[vars]\n",
    "\n",
    "bank_train.head()\n",
    "\n",
    "# Identify how many outliers there are and identify the most extreme outlier\n",
    "duration_outliers = bank_train.query(\"duration_z < -3 | duration_z > 3\").sort_values([\"duration_z\"], ascending=False)\n",
    "\n",
    "low = len(duration_outliers)\n",
    "idx = duration_outliers.iloc[0][\"index\"]\n",
    "value = duration_outliers.iloc[0][\"duration_z\"]\n",
    "\n",
    "print(f\"There are {low:,} outliers. The greatest of which is at index {idx} with a value of {value:.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. Do the following for the `campaign` field.\n",
    "\n",
    "    1. Standardize the variable.\n",
    "    1. Identify how many outliers there are and identify the most extreme outlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the variable\n",
    "bank_train[\"campaign_z\"] = stats.zscore(bank_train[\"campaign\"])\n",
    "\n",
    "vars = bank_train.columns.tolist()\n",
    "idx = bank_train.columns.get_loc(\"campaign\")\n",
    "vars = vars[0 : idx + 1] + vars[-1:] + vars[idx + 1 : -1]\n",
    "bank_train = bank_train[vars]\n",
    "\n",
    "bank_train.head()\n",
    "\n",
    "# Identify how many outliers there are and identify the most extreme outlier\n",
    "campaign_outliers = bank_train.query(\"campaign_z < -3 | campaign_z > 3\").sort_values([\"campaign_z\"], ascending=False)\n",
    "\n",
    "low = len(campaign_outliers)\n",
    "idx = campaign_outliers.iloc[0][\"index\"]\n",
    "value = campaign_outliers.iloc[0][\"campaign_z\"]\n",
    "\n",
    "print(f\"There are {low:,} outliers. The greatest of which is at index {idx} with a value of {value:.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands-On Analysis\n",
    "\n",
    "For Exercises 21–25, work with the `Nutrition_subset` data set. The data set contains the weight in grams along with the amount of saturated fat and the amount of cholesterol for a set of 961 foods. Use either Python or R to solve each problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food item</th>\n",
       "      <th>weight_in_grams</th>\n",
       "      <th>saturated_fat</th>\n",
       "      <th>cholesterol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GELATIN; DRY                  1 ENVELP</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEAWEED; SPIRULINA; DRIED     1 OZ</td>\n",
       "      <td>28.35</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YEAST; BAKERS; DRY; ACTIVE    1 PKG</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PARMESAN CHEESE; GRATED       1 OZ</td>\n",
       "      <td>28.35</td>\n",
       "      <td>5.4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PARMESAN CHEESE; GRATED       1 CUP</td>\n",
       "      <td>100.00</td>\n",
       "      <td>19.1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                food item  weight_in_grams  saturated_fat  \\\n",
       "0  GELATIN; DRY                  1 ENVELP             7.00            0.0   \n",
       "1  SEAWEED; SPIRULINA; DRIED     1 OZ                28.35            0.8   \n",
       "2  YEAST; BAKERS; DRY; ACTIVE    1 PKG                7.00            0.0   \n",
       "3  PARMESAN CHEESE; GRATED       1 OZ                28.35            5.4   \n",
       "4  PARMESAN CHEESE; GRATED       1 CUP              100.00           19.1   \n",
       "\n",
       "   cholesterol  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3           22  \n",
       "4           79  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "nutrition = pd.read_csv(\"data/nutrition_subset\", index_col=False)\n",
    "\n",
    "nutrition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. The elements in the data set are food items of various sizes, ranging from a teaspoon of cinnamon to an entire carrot cake.\n",
    "\n",
    "    1. Sort the data set by the saturated fat (`saturated_fat`) and produce a listing of the five food items highest in saturated fat.\n",
    "    1. Comment on the validity of comparing food items of different sizes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data set by the saturated fat (`saturated_fat`) and produce a listing of the five food items highest in saturated fat.\n",
    "nutrition = nutrition.sort_values([\"saturated_fat\"], ascending=False)\n",
    "\n",
    "# Comment on the validity of comparing food items of different sizes.\n",
    "print(\n",
    "    \"\"\"Comparing foods of different quantities is essentially meaningless as a food that\n",
    "is high in saturated fat may appear to have very little if we are considering a small\n",
    "portion and vise versa.\"\"\"\n",
    ")\n",
    "\n",
    "nutrition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. Derive a new variable, `saturated_fat_per_gram`, by dividing the amount of saturated fat by the weight in grams.\n",
    "\n",
    "    1. Sort the data set by `saturated_fat_per_gram` and produce a listing of the five food items highest in saturated fat per gram.\n",
    "    1. Which food has the most saturated fat per gram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data set by `saturated_fat_per_gram` and produce a listing of the five food items highest in saturated fat per gram.\n",
    "nutrition[\"saturated_fat_per_gram\"] = nutrition[\"saturated_fat\"] / nutrition[\"weight_in_grams\"]\n",
    "nutrition = nutrition.sort_values([\"saturated_fat_per_gram\"], ascending=False)\n",
    "\n",
    "# Which food has the most saturated fat per gram?\n",
    "print(\"\"\"Butter has the highest amount of saturated fat per gram.\"\"\")\n",
    "\n",
    "nutrition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. Derive a new variable, cholesterol_per_gram.\n",
    "\n",
    "    1. Sort the data set by `cholesterol_per_gram` and produce a listing of the five food items highest in cholesterol fat per gram.\n",
    "    1. Which food has the most cholesterol fat per gram?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data set by `cholesterol_per_gram` and produce a listing of the five food items highest in cholesterol fat per gram.\n",
    "nutrition[\"cholesterol_per_gram\"] = nutrition[\"cholesterol\"] / nutrition[\"weight_in_grams\"]\n",
    "nutrition = nutrition.sort_values(\"cholesterol_per_gram\", ascending=False)\n",
    "\n",
    "# Which food has the most cholesterol fat per gram?\n",
    "print(\"\"\"Egg yolks have the highest amount of cholesterol per gram.\"\"\")\n",
    "\n",
    "nutrition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. Standardize the field `saturated_fat_per_gram`. Produce a listing of all the food items that are outliers at the high end of the scale. How many food items are outliers at the low end of the scale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition[\"saturated_fat_per_gram_z\"] = stats.zscore(nutrition[\"saturated_fat_per_gram\"])\n",
    "\n",
    "high = nutrition.query(\"saturated_fat_per_gram_z > 3\").shape[0]\n",
    "print(f\"There are {high:,} foods on the high end of the scale. They are:\")\n",
    "print()\n",
    "print(nutrition.query(\"saturated_fat_per_gram_z > 3\")[\"food item\"])\n",
    "\n",
    "low = nutrition.query(\"saturated_fat_per_gram_z < -3\").shape[0]\n",
    "print()\n",
    "print(f\"There are {low:,} foods on the low end of the scale.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. Standardize the field `cholesterol_per_gram`. Produce a listing of all the food items that are outliers at the high end of the scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition[\"cholesterol_per_gram_z\"] = stats.zscore(nutrition[\"cholesterol_per_gram\"])\n",
    "\n",
    "print(nutrition.query(\"cholesterol_per_gram_z > 3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Exercises 26–30, work with the `adult_ch3_training` data set. The response is whether income exceeds $50,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "adult = pd.read_csv(\"data/adult_ch3_training\", index_col=False)\n",
    "\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26. Add a record index field to the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult.insert(0, \"index\", range(adult.shape[0]))\n",
    "\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27. Determine whether any outliers exist for the `education` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult[\"education_z\"] = stats.zscore(adult[\"education\"])\n",
    "\n",
    "ed_outliers = adult.query(\"education_z > 3 | education_z < -3\")\n",
    "\n",
    "print(f\"There are {ed_outliers.shape[0]} outliers in the data set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28. Do the following for the `age` field.\n",
    "\n",
    "    1. Standardize the variable.\n",
    "    1. Identify how many outliers there are and identify the most extreme outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult[\"age_z\"] = stats.zscore(adult[\"age\"])\n",
    "\n",
    "age_outliers = adult.query(\"age_z > 3 | age_z < -3\").sort_values([\"age_z\"], ascending=False)\n",
    "\n",
    "print(f\"There are {age_outliers.shape[0]} outliers in the data set.\")\n",
    "print(f\"The most extreme is:\\n{age_outliers.iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29. Derive a flag for `capital‐gain`, called `capital‐gain‐flag`, which equals 0 for capital gain equals zero, and 1 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult[\"capital-gain-flag\"] = adult[\"capital-gain\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30. Age anomaly? Select only records with `age` at least 80. Construct a histogram of age. Explain what you see in one sentence and why it is like that in another sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eighty_plus = adult.query(\"age >= 80\")\n",
    "\n",
    "plt.hist(eighty_plus[\"age\"], edgecolor=\"black\")\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.title(\"Distribution of ages over 80\")\n",
    "\n",
    "print(\n",
    "    \"\"\"There are an inordinate number of rows where age = 90. This is likely due to all\n",
    "ages > 90 being recorded as 90.\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
